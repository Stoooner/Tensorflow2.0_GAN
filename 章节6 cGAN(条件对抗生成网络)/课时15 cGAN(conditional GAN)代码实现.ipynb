{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 课时15 cGAN(conditional GAN)代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 导入MNIST数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting E:\\SoftWare_Installing\\Pycharm\\Pycharm WorkPlace\\GAN生成对抗网络入门与实战\\data\\MNIST\\train-images-idx3-ubyte.gz\n",
      "Extracting E:\\SoftWare_Installing\\Pycharm\\Pycharm WorkPlace\\GAN生成对抗网络入门与实战\\data\\MNIST\\train-labels-idx1-ubyte.gz\n",
      "Extracting E:\\SoftWare_Installing\\Pycharm\\Pycharm WorkPlace\\GAN生成对抗网络入门与实战\\data\\MNIST\\t10k-images-idx3-ubyte.gz\n",
      "Extracting E:\\SoftWare_Installing\\Pycharm\\Pycharm WorkPlace\\GAN生成对抗网络入门与实战\\data\\MNIST\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('E:\\SoftWare_Installing\\Pycharm\\Pycharm WorkPlace\\GAN生成对抗网络入门与实战\\data\\MNIST', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 定义模型搭建需要的各个组件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 接收输入\n",
    "def get_inputs(noise_dim, image_height, image_width, image_depth):\n",
    "    inputs_real = tf.placeholder(dtype=tf.float32, \n",
    "                                 shape=[None, image_height, image_width, image_depth],\n",
    "                                 name='inputs_real')\n",
    "    inputs_noise = tf.placeholder(dtype=tf.float32, \n",
    "                                  shape=[None, noise_dim],\n",
    "                                  name='inputs_noise')\n",
    "    # 这里condition_label.shape = [None, 10]是因为one_hot=True\n",
    "    condition_label = tf.placeholder(dtype=tf.float32, shape=[None, 10], name='condition_label')\n",
    "    return inputs_real, inputs_noise, condition_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义生成器\n",
    "def generator(noise_img, output_dim, condition_label, is_train=True):\n",
    "    with tf.variable_scope(name_or_scope='generator', reuse=(not is_train)):\n",
    "        # 第一层为全连接层，将噪声数据的维度从100 x 1 ===> 4 x 4 x 512\n",
    "        # 在传入网络之前需要将noise和condition合并起来\n",
    "        noise_img_ = tf.concat(values=[noise_img, condition_label], axis=1)\n",
    "        print(noise_img_.shape, noise_img.shape, condition_label.shape)\n",
    "        layer_1 = tf.layers.dense(noise_img_, 4*4*512)\n",
    "        layer_1 = tf.reshape(layer_1, [-1, 4, 4, 512])\n",
    "        # batch_normalization\n",
    "        layer_1 = tf.layers.batch_normalization(layer_1, training=is_train)\n",
    "        layer_1 = tf.nn.relu(layer_1)\n",
    "        # dropout\n",
    "        layer_1 = tf.nn.dropout(layer_1, keep_prob=0.8)\n",
    "        \n",
    "        # 4 x 4 x 512 ===> 7 x 7 x 256\n",
    "        layer_2 = tf.layers.conv2d_transpose(inputs=layer_1, filters=256, \n",
    "                                             kernel_size=4,\n",
    "                                             strides=1, padding='valid')\n",
    "        layer_2 = tf.layers.batch_normalization(layer_2, training=is_train)\n",
    "        layer_2 = tf.nn.relu(layer_2)\n",
    "        layer_2 = tf.nn.dropout(layer_2, keep_prob=0.8)\n",
    "        \n",
    "        # 7 x 7 x 256 ===> 14 x 14 x 128\n",
    "        layer_3 = tf.layers.conv2d_transpose(inputs=layer_2, filters=128, \n",
    "                                             kernel_size=3,\n",
    "                                             strides=2, padding='same')\n",
    "        layer_3 = tf.layers.batch_normalization(layer_3, training=is_train)\n",
    "        layer_3 = tf.nn.relu(layer_3)\n",
    "        layer_3 = tf.nn.dropout(layer_3, keep_prob=0.8)\n",
    "        \n",
    "        # 14 x 14 x 128 ===> 28 x 28 x 1\n",
    "        logits = tf.layers.conv2d_transpose(inputs=layer_3, filters=output_dim,\n",
    "                                            kernel_size=3,\n",
    "                                            strides=2, padding='same')\n",
    "        outputs = tf.tanh(logits)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义判别器\n",
    "def discriminator(inputs_img, condition_label, reuse=False, alpha=0.01):\n",
    "    with tf.variable_scope(name_or_scope='discriminator', reuse=reuse):\n",
    "        # 图像在输入到网络之前需要与condition_label进行合并，因此必须先进行flatten，\n",
    "        # 然后才好进行合并，最后合并完成了才好传入到网络\n",
    "        flatten_0 = tf.reshape(inputs_img, (-1, 28*28*1))\n",
    "        flatten_1 = tf.concat(values=[flatten_0, condition_label], axis=1)\n",
    "        layer_0 = tf.layers.dense(flatten_1, 28*28*1)\n",
    "        layer_0_ = tf.reshape(layer_0, [-1, 28, 28, 1])\n",
    "        \n",
    "        \n",
    "        # [28, 28, 1] ===> [14, 14, 128]\n",
    "        # 第一层不加BN\n",
    "        layer_1 = tf.layers.conv2d(inputs=layer_0_, filters=128, kernel_size=3,\n",
    "                                   strides=2, padding='same')\n",
    "        layer_1 = tf.maximum(alpha*layer_1, layer_1)\n",
    "        layer_1 = tf.nn.dropout(layer_1, keep_prob=0.8)\n",
    "        \n",
    "        # [14, 14, 128] ===> [7, 7, 256]\n",
    "        layer_2 = tf.layers.conv2d(inputs=layer_1, filters=256, kernel_size=3,\n",
    "                                   strides=2, padding='same')\n",
    "        layer_2 = tf.layers.batch_normalization(layer_2, training=True)\n",
    "        layer_2 = tf.maximum(alpha*layer_2, layer_2)\n",
    "        layer_2 = tf.nn.dropout(layer_2, keep_prob=0.8)\n",
    "        \n",
    "        # [7, 7, 256] ===> [4, 4, 512]\n",
    "        layer_3 = tf.layers.conv2d(inputs=layer_2, filters=512, kernel_size=3,\n",
    "                                   strides=2, padding='same')\n",
    "        layer_3 = tf.layers.batch_normalization(layer_3, training=True)\n",
    "        layer_3 = tf.maximum(alpha*layer_3, layer_3)\n",
    "        layer_3 = tf.nn.dropout(layer_3, keep_prob=0.8)\n",
    "        \n",
    "        # [4, 4, 512] ===> [4*4*512, 1]\n",
    "        flatten = tf.reshape(layer_3, (-1, 4*4*512))\n",
    "        logits = tf.layers.dense(flatten, 1)\n",
    "        outputs = tf.sigmoid(logits)\n",
    "        \n",
    "        return logits, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取loss值\n",
    "def get_loss(inputs_real, inputs_noise, condition_label, image_depth, smooth=0.1):\n",
    "    g_outputs = generator(inputs_noise, image_depth, condition_label, is_train=True)\n",
    "    d_logits_real, d_output_real = discriminator(inputs_real, condition_label)\n",
    "    d_logits_fake, d_output_fake = discriminator(g_outputs, condition_label, reuse=True)\n",
    "    \n",
    "    # 计算loss值\n",
    "    g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n",
    "                                                                    labels=tf.ones_like(d_output_fake)*(1-smooth)))\n",
    "    \n",
    "    d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real,\n",
    "                                                                         labels=tf.ones_like(d_output_real)*(1-smooth)))\n",
    "    d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n",
    "                                                                         labels=tf.zeros_like(d_output_fake)))\n",
    "    d_loss = tf.add(d_loss_real, d_loss_fake)\n",
    "    \n",
    "    return g_loss, d_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置优化器\n",
    "def get_optimizer(g_loss, d_loss, beta1=0.4, learning_rate=0.001):\n",
    "    train_vars = tf.trainable_variables()\n",
    "    g_vars = [var for var in train_vars if var.name.startswith('generator')]\n",
    "    d_vars = [var for var in train_vars if var.name.startswith('discriminator')]\n",
    "    \n",
    "    # optimizers\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "        g_opt = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(g_loss, var_list=g_vars)\n",
    "        d_opt = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(d_loss, var_list=d_vars)\n",
    "    \n",
    "    return g_opt, d_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单独创建一个绘图函数用于后面绘制每一步生成器产生的图像\n",
    "def plot_image(samples):\n",
    "    # 由于生成器采用的激活函数是[-1, 1]之间，为了能够更好的绘图\n",
    "    # 需要将其转换到[0, 1]之间，因此有下面一行的操作\n",
    "    samples = (samples + 1) / 2\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=25, sharex=True, \n",
    "                             sharey=True, figsize=(50, 2))\n",
    "    for img, ax in zip(samples, axes):\n",
    "        ax.imshow(img.reshape((28, 28)), cmap='Greys_r')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    fig.tight_layout(pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 展示生成器的生成结果\n",
    "def show_generator_output(sess, n_images, inputs_noise, output_dim, condition_label):\n",
    "    noise_shape = inputs_noise.get_shape().as_list()[-1]\n",
    "    # 生成噪声图片\n",
    "    example_noise = np.random.uniform(-1, 1, size=[n_images, noise_shape])\n",
    "    condition_label_test = mnist.train.labels[50: 75]\n",
    "    \n",
    "    samples = sess.run(generator(inputs_noise, output_dim, condition_label, False),\n",
    "                       feed_dict={inputs_noise: example_noise, \n",
    "                                  condition_label: condition_label_test})\n",
    "    result = np.squeeze(samples, -1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义参数\n",
    "batch_size = 64\n",
    "noise_size = 100\n",
    "epochs = 5\n",
    "n_samples = 25\n",
    "learning_rate = 0.01\n",
    "beta1 = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(noise_size, data_shape, batch_size, n_samples):\n",
    "    # 存储loss\n",
    "    losses = []\n",
    "    step = 0\n",
    "    \n",
    "    inputs_real, inputs_noise, condition_label = get_inputs(noise_size, data_shape[1], data_shape[2], data_shape[3])\n",
    "    g_loss, d_loss = get_loss(inputs_real, inputs_noise, condition_label, data_shape[-1])\n",
    "    g_train_opt, d_train_opt = get_optimizer(g_loss, d_loss, beta1, learning_rate)\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for e in range(epochs):\n",
    "            for batch_i in range(mnist.train.num_examples // batch_size):\n",
    "                step += 1\n",
    "                batch_imgase_, batch_labels = mnist.train.next_batch(batch_size)\n",
    "                batch_images = batch_imgase_.reshape((batch_size, \n",
    "                                                      data_shape[1],\n",
    "                                                      data_shape[2], \n",
    "                                                      data_shape[3]))\n",
    "                # [-1, 1]\n",
    "                batch_images = batch_images*2 - 1\n",
    "                \n",
    "                # generator的输入噪声\n",
    "                batch_noise = np.random.uniform(-1, 1, size=(batch_size, noise_size))\n",
    "\n",
    "                # Run optimizers\n",
    "                _ = sess.run(g_train_opt, feed_dict={inputs_real:batch_images,\n",
    "                                                     inputs_noise:batch_noise,\n",
    "                                                     condition_label:batch_labels})\n",
    "                _ = sess.run(d_train_opt, feed_dict={inputs_real:batch_images,\n",
    "                                                     inputs_noise:batch_noise,\n",
    "                                                     condition_label:batch_labels})\n",
    "                \n",
    "                if step % 101 == 0:\n",
    "                    saver.save(sess, '../tf_saver_files/class_6_cGANS/generator.ckpt')\n",
    "                    train_loss_d = d_loss.eval({inputs_real:batch_images,\n",
    "                                                inputs_noise:batch_noise,\n",
    "                                                condition_label:batch_labels})\n",
    "                    train_loss_g = g_loss.eval({inputs_real:batch_images,\n",
    "                                                inputs_noise:batch_noise,\n",
    "                                                condition_label:batch_labels})\n",
    "                    losses.append((train_loss_d, train_loss_g))\n",
    "                    \n",
    "                    # 显示图片\n",
    "                    samples = show_generator_output(sess, n_samples, \n",
    "                                                    inputs_noise, data_shape[-1],\n",
    "                                                    condition_label)\n",
    "                    plot_image(samples)\n",
    "                    \n",
    "                    print('Epoch is %i/%i'%(e+1, epochs),\n",
    "                          'Discriminator Loss is %.3f'%(train_loss_d),\n",
    "                          ', Generator Loss is %.3f'%(train_loss_g))\n",
    "            saver.save(sess, '../tf_saver_files/class_6_cGANS/generator.ckpt')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-6e404451fc98>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-35-3ab61f532c03>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(noise_size, data_shape, batch_size, n_samples)\u001b[0m\n\u001b[0;32m     28\u001b[0m                 _ = sess.run(g_train_opt, feed_dict={inputs_real:batch_images,\n\u001b[0;32m     29\u001b[0m                                                      \u001b[0minputs_noise\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_noise\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                                                      condition_label:batch_labels})\n\u001b[0m\u001b[0;32m     31\u001b[0m                 _ = sess.run(d_train_opt, feed_dict={inputs_real:batch_images,\n\u001b[0;32m     32\u001b[0m                                                      \u001b[0minputs_noise\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_noise\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\SoftWare_Installing\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\SoftWare_Installing\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\SoftWare_Installing\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\SoftWare_Installing\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\SoftWare_Installing\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\SoftWare_Installing\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    train(noise_size, [-1, 28, 28, 1], batch_size, n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = [-1, 28, 28, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_real, inputs_noise, condition_label = get_inputs(noise_size, data_shape[1], data_shape[2], data_shape[3])\n",
    "g_loss, d_loss = get_loss(inputs_real, inputs_noise, condition_label, data_shape[-1])\n",
    "g_train_opt, d_train_opt = get_optimizer(g_loss, d_loss, beta1, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "sess=tf.Session()\n",
    "saver.restore(sess, tf.train.latest_checkpoint('../tf_saver_files/class_6_cGANS/generator.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = show_generator_output(sess, 25, inputs_noise, data_shape[-1], condition_label)\n",
    "plot_images(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(mnist.train.labels[50:75], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每次运行下面两句话都会生成标签相同的数字图片，但是由于噪声不同，所以每次产生的图片的样式会有变化\n",
    "samples = show_generator_output(sess, 25, inputs_noise, data_shape[-1], condition_label)\n",
    "plot_images(samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python36",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
