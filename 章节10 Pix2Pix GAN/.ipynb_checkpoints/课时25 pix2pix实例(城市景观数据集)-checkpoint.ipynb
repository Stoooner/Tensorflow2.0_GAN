{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 课时25 pix2pixGAN实例(TF2.0城市街景数据集)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import glob\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">1. **需要注意的是，原始的GAN的生成器网络接收的输入的一个一维的向量，因此整体的生成器网络其实只是一个AutoEncode的Decode部分；而pix2pixGAN的生成器网络部分接收的输入是一个完整的图片，因此pix2pixGAN的生成器网络是一个完整的AutoEncode网络。当我们使用pix2pixGAN网络进行类似图像翻译的任务的时候，输入与输出之间会共享很多的信息，例如图像轮廓信息等。而这个AutoEncode生成器网络在使用普通的卷积网络进行传递的信息传递的时候，每一层网络都要存储这些信息，会很容易出错，因此为了避免这样的情况发生，我们使用U-Net网络来搭建生成器网络。**\n",
    ">2. **pix2pixGAN本质上是一种图像翻译模型。也就是把一张图像翻译成另一张图像。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 定义数据集读取和预处理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_path = '../'\n",
    "train_images_path_list = glob.glob(pathname=train_images_path)\n",
    "len(train_images_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_path_list[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show(tf.keras.preprocessing.image.load_img(train_images_path_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义图片解码函数\n",
    "def read_jpg(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义归一化函数\n",
    "def normalize(mask, image):\n",
    "    mask = tf.cast(mask, tf.float32) / 127.5 - 1\n",
    "    image = tf.cast(image, tf.float32) / 127.5 - 1\n",
    "    return mask, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义图像加载函数\n",
    "def load_image(image_path):\n",
    "    image = read_jpg(image_path)\n",
    "    width = tf.shape(image)[1]\n",
    "    # 由于image和它对应的mask是合并到一张图片的，因此需要从中间切分开来\n",
    "    w = w // 2\n",
    "    input_mask = image[:, w:, :]\n",
    "    input_image = image[:, :w, :]\n",
    "    \n",
    "    # 下面两个resize的操作实际上没有什么实质性的影响，因为mask和image本身就是[256, 256, 3]的\n",
    "    # 但是下面这两个操作能够使得mask和image在做成datasets之后可以正常显示两个的shape大小\n",
    "    input_mask = tf.image.resize(input_mask, (256, 256))\n",
    "    input_image = tf.image.resize(input_image, (256, 256))\n",
    "    \n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        input_image = tf.image.flip_left_right(input_image)\n",
    "        input_mask = tf.image.flip_left_right(input_mask)\n",
    "    input_mask, input_image = normalize(input_mask, input_image)\n",
    "    return input_mask, input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = len(train_images_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建datasets\n",
    "dataset = tf.data.Dataset.from_tensor_slices(train_images_path_list)\n",
    "dataset = dataset.map(load_image)\n",
    "dataset = dataset.shuffer(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "# GPU在训练当前批次的时候，使用prefetch函数能够让CPU去预加载另一批数据\n",
    "dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先展示一下图像（需要注意的是dataset.take(1)这里代表的是取一个batch的数据）\n",
    "for mask, img in dataset.take(1):\n",
    "    plt.subplot(1, 2, 1)\n",
    "    # 这里使用tf.keras.preprocessing.image.array_to_img是因为到这里mask和image已经归一化了，存在你显示不正常的情况\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(mask[0]))\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(image[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上面训练数据加载完毕之后开始加载测试数据\n",
    "test_images_path = '../'\n",
    "test_images_path_list = glob.glob(pathname=test_images_path)\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices(test_images_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义图像加载函数\n",
    "def load_image_test(image_path):\n",
    "    image = read_jpg(image_path)\n",
    "    width = tf.shape(image)[1]\n",
    "    # 由于image和它对应的mask是合并到一张图片的，因此需要从中间切分开来\n",
    "    w = w // 2\n",
    "    input_mask = image[:, w:, :]\n",
    "    input_image = image[:, :w, :]\n",
    "    \n",
    "    # 下面两个resize的操作实际上没有什么实质性的影响，因为mask和image本身就是[256, 256, 3]的\n",
    "    # 但是下面这两个操作能够使得mask和image在做成datasets之后可以正常显示两个的shape大小\n",
    "    input_mask = tf.image.resize(input_mask, (256, 256))\n",
    "    input_image = tf.image.resize(input_image, (256, 256))\n",
    "    \n",
    "    input_mask, input_image = normalize(input_mask, input_image)\n",
    "    return input_mask, input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = dataset_test.map(load_image_test)\n",
    "dataset_test = dataset_test.batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先展示一下图像（需要注意的是dataset.take(1)这里代表的是取一个batch的数据）\n",
    "for mask, img in dataset_test.take(1):\n",
    "    plt.subplot(1, 2, 1)\n",
    "    # 这里使用tf.keras.preprocessing.image.array_to_img是因为到这里mask和image已经归一化了，存在你显示不正常的情况\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(mask[0]))\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(image[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 定义上采用和下采样模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_sampling(filters, kernel_size, apply_bn_flag=True):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=2, \n",
    "                               padding='same', use_bias=False))\n",
    "    if apply_bn_flag:\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def up_sampling(filters, kernel_size, apply_dropout_flag=False):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2DTranspose(filters=filters, kernel_size=kernel_size, \n",
    "                                              strides=2, padding='same', use_bias=False))\n",
    "\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    if apply_dropout_flag:\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.5))\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义Generator模型(U-Net架构)\n",
    "def Generator():\n",
    "    inputs = tf.keras.layers.Input(shape=(256, 256, 3))\n",
    "    down_stach = [\n",
    "        # [256, 256, 3] ===> [128, 128, 64]\n",
    "        down_sampling(filters=64, kernel_size=3, apply_bn_flag=False),\n",
    "        # [128, 128, 64] ===> [64, 64, 128]\n",
    "        down_sampling(filters=128, kernel_size=3),\n",
    "        # [64, 64, 128] ===> [32, 32, 256]\n",
    "        down_sampling(filters=256, kernel_size=3),\n",
    "        # [32, 32, 256] ===> [16, 16, 512]\n",
    "        down_sampling(filters=512, kernel_size=3),\n",
    "        \n",
    "        # [16, 16, 512] ===> [8, 8, 512]\n",
    "        down_sampling(filters=512, kernel_size=3),\n",
    "        # [8, 8, 512] ===> [4, 4, 512]\n",
    "        down_sampling(filters=512, kernel_size=3),\n",
    "        # [4, 4, 512] ===> [2, 2, 512]\n",
    "        down_sampling(filters=512, kernel_size=3),\n",
    "        # [2, 2, 512] ===> [1, 1, 512]\n",
    "        down_sampling(filters=512, kernel_size=3)\n",
    "    ]\n",
    "    \n",
    "    up_stach = [\n",
    "        # [1, 1, 512] ===> [2, 2, 512]\n",
    "        up_sampling(filters=512, kernel_size=3, apply_dropout_flag=True),\n",
    "        # [2, 2, 512] ===> [4, 4, 512]\n",
    "        up_sampling(filters=512, kernel_size=3, apply_dropout_flag=True),\n",
    "        # [4, 4, 512] ===> [8, 8, 512]\n",
    "        up_sampling(filters=512, kernel_size=3, apply_dropout_flag=True),\n",
    "        # [8, 8, 512] ===> [16, 16, 512]\n",
    "        up_sampling(filters=512, kernel_size=3),\n",
    "        \n",
    "        # [16, 16, 512] ===> [32, 32, 256]\n",
    "        up_sampling(filters=256, kernel_size=3),\n",
    "        # [32, 32, 256] ===> [64, 64, 128]\n",
    "        up_sampling(filters=128, kernel_size=3),\n",
    "        # [64, 64, 128] ===> [128, 128, 64]\n",
    "        up_sampling(filters=64, kernel_size=3)\n",
    "    ]\n",
    "    \n",
    "    x = inputs\n",
    "    skips = []\n",
    "    for down in down_stach:\n",
    "        x = down(x)\n",
    "        skips.append(x)\n",
    "    skips = reversed(skips[:-1])\n",
    "    \n",
    "    for up, skip in zip(up_stach, skips):\n",
    "        x = up(x)\n",
    "        x = tf.keras.layers.Concatenate([x, skip])\n",
    "    # 由于图片的预处理中，对图片进行了[-1, 1]区间的归一化处理，因此使用activation='tanh'\n",
    "    x = tf.keras.layers.Conv2DTranspose(filters=3, kernel_size=3, strides=2, \n",
    "                                        padding='same', activation='tanh')(x)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
