{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 课时13 DCGAN代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 导入MNIST数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-a5ee3e96278b>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From E:\\SoftWare_Installing\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From E:\\SoftWare_Installing\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting E:\\SoftWare_Installing\\Pycharm\\Pycharm WorkPlace\\GAN生成对抗网络入门与实战\\data\\MNIST\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From E:\\SoftWare_Installing\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting E:\\SoftWare_Installing\\Pycharm\\Pycharm WorkPlace\\GAN生成对抗网络入门与实战\\data\\MNIST\\train-labels-idx1-ubyte.gz\n",
      "Extracting E:\\SoftWare_Installing\\Pycharm\\Pycharm WorkPlace\\GAN生成对抗网络入门与实战\\data\\MNIST\\t10k-images-idx3-ubyte.gz\n",
      "Extracting E:\\SoftWare_Installing\\Pycharm\\Pycharm WorkPlace\\GAN生成对抗网络入门与实战\\data\\MNIST\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From E:\\SoftWare_Installing\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('E:\\SoftWare_Installing\\Pycharm\\Pycharm WorkPlace\\GAN生成对抗网络入门与实战\\data\\MNIST', one_hot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 定义模型搭建需要的各个组件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 接收输入\n",
    "def get_inputs(noise_dim, image_height, image_width, image_depth):\n",
    "    inputs_real = tf.placeholder(dtype=tf.float32, \n",
    "                                 shape=[None, image_height, image_width, image_depth],\n",
    "                                 name='inputs_real')\n",
    "    inputs_noise = tf.placeholder(dtype=tf.float32, \n",
    "                                  shape=[None, noise_dim],\n",
    "                                  name='inputs_noise')\n",
    "    return inputs_real, inputs_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义生成器\n",
    "def generator(noise_img, output_dim, is_train=True):\n",
    "    with tf.variable_scope(name_or_scope='generator', reuse=(not is_train)):\n",
    "        # 第一层为全连接层，将噪声数据的维度从100 x 1 ===> 4 x 4 x 512\n",
    "        layer_1 = tf.layers.dense(noise_img, 4*4*512)\n",
    "        layer_1 = tf.reshape(layer_1, [-1, 4, 4, 512])\n",
    "        # batch_normalization\n",
    "        layer_1 = tf.layers.batch_normalization(layer_1, training=is_train)\n",
    "        layer_1 = tf.nn.relu(layer_1)\n",
    "        # dropout\n",
    "        layer_1 = tf.nn.dropout(layer_1, keep_prob=0.8)\n",
    "        \n",
    "        # 4 x 4 x 512 ===> 7 x 7 x 256\n",
    "        layer_2 = tf.layers.conv2d_transpose(inputs=layer_1, filters=256, \n",
    "                                             kernel_size=4,\n",
    "                                             strides=1, padding='valid')\n",
    "        layer_2 = tf.layers.batch_normalization(layer_2, training=is_train)\n",
    "        layer_2 = tf.nn.relu(layer_2)\n",
    "        layer_2 = tf.nn.dropout(layer_2, keep_prob=0.8)\n",
    "        \n",
    "        # 7 x 7 x 256 ===> 14 x 14 x 128\n",
    "        layer_3 = tf.layers.conv2d_transpose(inputs=layer_2, filters=128, \n",
    "                                             kernel_size=3,\n",
    "                                             strides=2, padding='same')\n",
    "        layer_3 = tf.layers.batch_normalization(layer_3, training=is_train)\n",
    "        layer_3 = tf.nn.relu(layer_3)\n",
    "        layer_3 = tf.nn.dropout(layer_3, keep_prob=0.8)\n",
    "        \n",
    "        # 14 x 14 x 128 ===> 28 x 28 x 1\n",
    "        logits = tf.layers.conv2d_transpose(inputs=layer_3, filters=output_dim,\n",
    "                                            kernel_size=3,\n",
    "                                            strides=2, padding='same')\n",
    "        outputs = tf.tanh(logits)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义判别器\n",
    "def discriminator(inputs_img, reuse=False, alpha=0.01):\n",
    "    with tf.variable_scope(name_or_scope='discriminator', reuse=reuse):\n",
    "        # [28, 28, 1] ===> [14, 14, 128]\n",
    "        # 第一层不加BN\n",
    "        layer_1 = tf.layers.conv2d(inputs=inputs_img, filters=128, kernel_size=3,\n",
    "                                   strides=2, padding='same')\n",
    "        layer_1 = tf.maximum(alpha*layer_1, layer_1)\n",
    "        layer_1 = tf.nn.dropout(layer_1, keep_prob=0.8)\n",
    "        \n",
    "        # [14, 14, 128] ===> [7, 7, 256]\n",
    "        layer_2 = tf.layers.conv2d(inputs=layer_1, filters=256, kernel_size=3,\n",
    "                                   strides=2, padding='same')\n",
    "        layer_2 = tf.layers.batch_normalization(layer_2, training=True)\n",
    "        layer_2 = tf.maximum(alpha*layer_2, layer_2)\n",
    "        layer_2 = tf.nn.dropout(layer_2, keep_prob=0.8)\n",
    "        \n",
    "        # [7, 7, 256] ===> [4, 4, 512]\n",
    "        layer_3 = tf.layers.conv2d(inputs=layer_2, filters=512, kernel_size=3,\n",
    "                                   strides=2, padding='same')\n",
    "        layer_3 = tf.layers.batch_normalization(layer_3, training=True)\n",
    "        layer_3 = tf.maximum(alpha*layer_3, layer_3)\n",
    "        layer_3 = tf.nn.dropout(layer_3, keep_prob=0.8)\n",
    "        \n",
    "        # [4, 4, 512] ===> [4*4*512, 1]\n",
    "        flatten = tf.reshape(layer_3, (-1, 4*4*512))\n",
    "        logits = tf.layers.dense(flatten, 1)\n",
    "        outputs = tf.sigmoid(logits)\n",
    "        \n",
    "        return logits, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取loss值\n",
    "def get_loss(inputs_real, inputs_noise, image_depth, smooth=0.1):\n",
    "    g_outputs = generator(inputs_noise, image_depth, is_train=True)\n",
    "    d_logits_real, d_output_real = discriminator(inputs_real)\n",
    "    d_logits_fake, d_output_fake = discriminator(g_outputs, reuse=True)\n",
    "    \n",
    "    # 计算loss值\n",
    "    g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n",
    "                                                                    labels=tf.ones_like(d_output_fake)*(1-smooth)))\n",
    "    \n",
    "    d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real,\n",
    "                                                                         labels=tf.ones_like(d_output_real)*(1-smooth)))\n",
    "    d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n",
    "                                                                         labels=tf.zeros_like(d_output_fake)))\n",
    "    d_loss = tf.add(d_loss_real, d_loss_fake)\n",
    "    \n",
    "    return g_loss, d_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置优化器\n",
    "def get_optimizer(g_loss, d_loss, beta1=0.4, learning_rate=0.001):\n",
    "    train_vars = tf.trainable_variables()\n",
    "    g_vars = [var for var in train_vars if var.name.startswith('generator')]\n",
    "    d_vars = [var for var in train_vars if var.name.startswith('discriminator')]\n",
    "    \n",
    "    # optimizers\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "        g_opt = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(g_loss, var_list=g_vars)\n",
    "        d_opt = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(d_loss, var_list=d_vars)\n",
    "    \n",
    "    return g_opt, d_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单独创建一个绘图函数用于后面绘制每一步生成器产生的图像\n",
    "def plot_image(samples):\n",
    "    # 由于生成器采用的激活函数是[-1, 1]之间，为了能够更好的绘图\n",
    "    # 需要将其转换到[0, 1]之间，因此有下面一行的操作\n",
    "    samples = (samples + 1) / 2\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=25, sharex=True, \n",
    "                             sharey=True, figsize=(50, 2))\n",
    "    for img, ax in zip(samples, axes):\n",
    "        ax.imshow(img.reshape((28, 28)), cmap='Greys_r')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    fig.tight_layout(pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 展示生成器的生成结果\n",
    "def show_generator_output(sess, n_images, inputs_noise, output_dim):\n",
    "    noise_shape = inputs_noise.get_shape().as_list()[-1]\n",
    "    # 生成噪声图片\n",
    "    example_noise = np.random.uniform(-1, 1, size=[n_images, noise_shape])\n",
    "    samples = sess.run(generator(inputs_noise, output_dim, False),\n",
    "                       feed_dict={inputs_noise: example_noise})\n",
    "    result = np.squeeze(samples, -1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义参数\n",
    "batch_size = 64\n",
    "noise_size = 100\n",
    "epochs = 5\n",
    "n_samples = 25\n",
    "learning_rate = 0.01\n",
    "beta1 = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(noise_size, data_shape, batch_size, n_samples):\n",
    "    # 存储loss\n",
    "    losses = []\n",
    "    step = 0\n",
    "    \n",
    "    inputs_real, inputs_noise = get_inputs(noise_size, data_shape[1], data_shape[2], data_shape[3])\n",
    "    g_loss, d_loss = get_loss(inputs_real, inputs_noise, data_shape[-1])\n",
    "    g_train_opt, d_train_opt = get_optimizer(g_loss, d_loss, beta1, learning_rate)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for e in range(epochs):\n",
    "            for batch_i in range(mnist.train.num_examples // batch_size):\n",
    "                step += 1\n",
    "                batch = mnist.train.next_batch(batch_size)\n",
    "                batch_images = batch[0].reshape((batch_size, data_shape[1],\n",
    "                                                 data_shape[2], data_shape[3]))\n",
    "                # [-1, 1]\n",
    "                batch_images = batch_images*2 - 1\n",
    "                # generator的输入噪声\n",
    "                batch_noise = np.random.uniform(-1, 1, size=(batch_size, noise_size))\n",
    "\n",
    "                # Run optimizers\n",
    "                _ = sess.run(g_train_opt, feed_dict={inputs_real:batch_images,\n",
    "                                                     inputs_noise:batch_noise})\n",
    "                _ = sess.run(d_train_opt, feed_dict={inputs_real:batch_images,\n",
    "                                                     inputs_noise:batch_noise})\n",
    "                \n",
    "                if step % 101 == 0:\n",
    "                    train_loss_d = d_loss.eval({inputs_real:batch_images,\n",
    "                                                inputs_noise:batch_noise})\n",
    "                    train_loss_g = g_loss.eval({inputs_real:batch_images,\n",
    "                                                inputs_noise:batch_noise})\n",
    "                    losses.append((train_loss_d, train_loss_g))\n",
    "                    \n",
    "                    # 显示图片\n",
    "                    samples = show_generator_output(sess, n_samples, \n",
    "                                                    inputs_noise, data_shape[-1])\n",
    "                    plot_image(samples)\n",
    "                    \n",
    "                    print('Epoch is %i/%i'%(e+1, epochs),\n",
    "                          'Discriminator Loss is %.3f'%(train_loss_d),\n",
    "                          ', Generator Loss is %.3f'%(train_loss_g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-6e404451fc98>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-80422d67ee4a>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(noise_size, data_shape, batch_size, n_samples)\u001b[0m\n\u001b[0;32m     23\u001b[0m                 \u001b[1;31m# Run optimizers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                 _ = sess.run(g_train_opt, feed_dict={inputs_real:batch_images,\n\u001b[1;32m---> 25\u001b[1;33m                                                      inputs_noise:batch_noise})\n\u001b[0m\u001b[0;32m     26\u001b[0m                 _ = sess.run(d_train_opt, feed_dict={inputs_real:batch_images,\n\u001b[0;32m     27\u001b[0m                                                      inputs_noise:batch_noise})\n",
      "\u001b[1;32mE:\\SoftWare_Installing\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\SoftWare_Installing\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\SoftWare_Installing\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\SoftWare_Installing\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\SoftWare_Installing\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\SoftWare_Installing\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    train(noise_size, [-1, 28, 28, 1], batch_size, n_samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python36",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
