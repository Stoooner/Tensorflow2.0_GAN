{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 课时50 基础CGAN(MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 读取数据以及数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2408d476b88>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 导入MNIST数据集\n",
    "(train_images, train_labels),(_, _) = tf.keras.datasets.mnist.load_data()\n",
    "plt.imshow(train_images[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对数据集进行预处理(数据归一化到[-1, 1])\n",
    "train_images = train_images/127.5 - 1\n",
    "# 这里CGAN采用的是DCGAN的结构，也就是卷积，因此需要将图片数据的第三个维度扩充起来\n",
    "train_images = np.expand_dims(train_images, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((28, 28, 1), ()), types: (tf.float64, tf.uint8)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将数据转换为datasets\n",
    "train_datasets = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "train_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义参量，并进行数据乱序和batch批次化\n",
    "BATCH_SIZE = 256\n",
    "noise_dim = 100\n",
    "train_datasets = train_datasets.shuffle(60000).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 定义生成器和判别器模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "    # 由于是两个输入，因此采用的是函数式API进行模型搭建\n",
    "    noise = tf.keras.layers.Input(shape=((noise_dim,)))\n",
    "    # 这里的标签值是一个单个的值，可以从train_datasets中可以看出来\n",
    "    condition_label = tf.keras.layers.Input(shape=(()))\n",
    "    \n",
    "    # 需要将输入的noise和condition_label进行合并concat\n",
    "    # 在进行合并之前，由于condition_label的shape=()，不太好进行合并\n",
    "    # 因此需要使用Embedding函数将其转换成我们制定shape的一个向量才好进行合并\n",
    "    # 其中output_dim=100代表将condition_label映射到长度与noise长度相同的维度\n",
    "    # https://www.jianshu.com/p/e8986d0ff4ff\n",
    "    # https://blog.csdn.net/claroja/article/details/95196612\n",
    "    # 需要注意的是input_dim代表的是整个数据的词汇表的个数，这里整个MNIST数据集也就是10个数字\n",
    "    # 而input_length则代表每次输入的序列的长度。\n",
    "    x = tf.keras.layers.Embedding(input_dim=10, output_dim=100, input_length=1)(condition_label)\n",
    "    x = tf.keras.layers.concatenate([noise, x])\n",
    "    # 合并完成之后，现在再利用全连接层将现在合并完之后的向量转换为合适shape的向量\n",
    "    # 方便后续以合适shape的向量为基准开始反卷积，知道反卷积到合适尺寸的图片大小\n",
    "    x = tf.keras.layers.Dense(units=3*3*128, use_bias=False)(x)\n",
    "    x = tf.keras.layers.Reshape(target_shape=(3, 3, 128))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    \n",
    "    # [7, 7, 64]\n",
    "    x = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=(3, 3), strides=(2, 2), \n",
    "                                        use_bias=False, padding='valid')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    \n",
    "    # [14, 14, 32]\n",
    "    x = tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=(3, 3), strides=(2, 2), \n",
    "                                        use_bias=False, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    \n",
    "    # [28, 28, 1]\n",
    "    x = tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=(3, 3), strides=(2, 2), \n",
    "                                        use_bias=False, padding='same')(x)\n",
    "    x = tf.keras.layers.Activation('tanh')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[noise, condition_label], outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_model():\n",
    "    # CGAN中discriminator在设计的时候对于condition_label的位置可以放在前面或者后面的\n",
    "    # 也就是说condition_label可以放在一开始图片输入的位置进行合并，然后一层层提取特征，知道最后进行概率判断\n",
    "    # 也可以等图片特征提取完毕开始准备传入到后续全连接层之前的时候进行合并，然后进行概率判断\n",
    "    input_image = tf.keras.layers.Input(shape=((28,28,1)))\n",
    "    condition_label = tf.keras.layers.Input(shape=(()))\n",
    "    \n",
    "    x = tf.keras.layers.Embedding(input_dim=10, output_dim=28*28, input_length=1)(condition_label)\n",
    "    x = tf.keras.layers.Reshape(target_shape=((28, 28, 1)))(x)\n",
    "    x = tf.keras.layers.concatenate([input_image, x])\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), strides=(2, 2), \n",
    "                               padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(rate=0.5)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), strides=(2, 2), \n",
    "                               padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(rate=0.5)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), strides=(2, 2), \n",
    "                               padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(rate=0.5)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    output_logits = tf.keras.layers.Dense(units=1)(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[input_image, condition_label], outputs=output_logits)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 定义损失函数及优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = generator_model()\n",
    "discriminator = discriminator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Binary_Crossentropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_image_outputs, fake_image_outputs):\n",
    "    real_image_loss = Binary_Crossentropy(y_true=tf.ones_like(real_image_outputs), y_pred=real_image_outputs)\n",
    "    fake_image_loss = Binary_Crossentropy(y_true=tf.zeros_like(fake_image_outputs), y_pred=fake_image_outputs)\n",
    "    return real_image_loss + fake_image_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_image_outputs):\n",
    "    return Binary_Crossentropy(y_true=tf.ones_like(fake_image_outputs), y_pred=fake_image_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 定义梯度更新函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    batchsize = labels.shape[0]\n",
    "    noise = tf.random.normal([batchsize, noise_dim])\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(inputs=(noise, labels), training=True)\n",
    "        fake_image_out = discriminator(inputs=(generated_images, labels), training=True)\n",
    "        real_image_out = discriminator(inputs=(images, labels), training=True)\n",
    "        \n",
    "        generator_loss_ = generator_loss(fake_image_out)\n",
    "        discriminator_loss_ = discriminator_loss(real_image_out, fake_image_out)\n",
    "        \n",
    "    generator_gradients = gen_tape.gradient(generator_loss_, generator.trainable_variables)\n",
    "    disciminator_gradients = disc_tape.gradient(discriminator_loss_, discriminator.trainable_variables)\n",
    "    \n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(disciminator_gradients, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 定义辅助绘图函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置模型训练后期查看模型效果的noise和label，这里取定了之后可以在后续展示的时候展示一样的图片\n",
    "noise_seed = tf.random.normal([10, noise_dim])\n",
    "label_seed = np.random.randint(0, 10, size=(10, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_generator_images(model, noise, label, epoch_num):\n",
    "    print('现在是第%i个epoch.'%(epoch_num))\n",
    "    generated_images = model(inputs=(noise, label), training=False)\n",
    "    # 将shape为[None, 28, 28, 1]的图像转换为[None, 28, 28]\n",
    "    generated_images = tf.squeeze(generated_images)\n",
    "    fig = plt.figure(figsize=(10, 1))\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(1, 10, i+1)\n",
    "        plt.imshow((generated_images[i, :, :, :]+1)/2)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 定义模型训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(datasets, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch is:', epoch)\n",
    "        for images_batch, labels_batch in datasets:\n",
    "            train_step(images_batch, labels_batch)\n",
    "            print('.', end=' ')\n",
    "        print()\n",
    "        if epoch % 10 == 0:\n",
    "            plot_generator_images(generator, noise_seed, label_seed, epoch)\n",
    "    plot_generator_images(generator, noise_seed, label_seed, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_datasets, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save('generate_v2.h5')\n",
    "num = 10\n",
    "noise_seed = tf.random.normal([num, noise_dim])\n",
    "cat_seed = np.arange(10).reshape(-1, 1)\n",
    "print(cat_seed.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_images(generator, noise_seed, cat_seed, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_seed = np.array([3]*10)\n",
    "generate_images(generator, noise_seed, cat_seed, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_seed = np.array([6]*10)\n",
    "generate_images(generator, noise_seed, cat_seed, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
