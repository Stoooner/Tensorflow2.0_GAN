{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 课时50 TF2.0版本基础CGAN(MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 读取数据以及数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd53041c190>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 251.565 248.518125\" width=\"251.565pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-01-07T14:00:59.716685</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 251.565 248.518125 \nL 251.565 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 26.925 224.64 \nL 244.365 224.64 \nL 244.365 7.2 \nL 26.925 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#pbbcf9dbe81)\">\n    <image height=\"218\" id=\"image958ea0bdbe\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\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\" y=\"-6.64\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m158d337ec7\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.807857\" xlink:href=\"#m158d337ec7\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(27.626607 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.636429\" xlink:href=\"#m158d337ec7\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 5 -->\n      <g transform=\"translate(66.455179 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.465\" xlink:href=\"#m158d337ec7\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 10 -->\n      <g transform=\"translate(102.1025 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"147.293571\" xlink:href=\"#m158d337ec7\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 15 -->\n      <g transform=\"translate(140.931071 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"186.122143\" xlink:href=\"#m158d337ec7\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 20 -->\n      <g transform=\"translate(179.759643 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"224.950714\" xlink:href=\"#m158d337ec7\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 25 -->\n      <g transform=\"translate(218.588214 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"mb5d136cd3d\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mb5d136cd3d\" y=\"11.082857\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0 -->\n      <g transform=\"translate(13.5625 14.882076)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mb5d136cd3d\" y=\"49.911429\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 5 -->\n      <g transform=\"translate(13.5625 53.710647)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mb5d136cd3d\" y=\"88.74\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 10 -->\n      <g transform=\"translate(7.2 92.539219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mb5d136cd3d\" y=\"127.568571\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 15 -->\n      <g transform=\"translate(7.2 131.36779)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mb5d136cd3d\" y=\"166.397143\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 20 -->\n      <g transform=\"translate(7.2 170.196362)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mb5d136cd3d\" y=\"205.225714\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 25 -->\n      <g transform=\"translate(7.2 209.024933)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 26.925 224.64 \nL 26.925 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 244.365 224.64 \nL 244.365 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 26.925 224.64 \nL 244.365 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 26.925 7.2 \nL 244.365 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pbbcf9dbe81\">\n   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "# 导入MNIST数据集\n",
    "(train_images, train_labels),(_, _) = tf.keras.datasets.mnist.load_data()\n",
    "plt.imshow(train_images[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对数据集进行预处理(数据归一化到[-1, 1])\n",
    "train_images = train_images/127.5 - 1\n",
    "# 这里CGAN采用的是DCGAN的结构，也就是卷积，因此需要将图片数据的第三个维度扩充起来，也可以使用reshap的方式\n",
    "# train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
    "train_images = np.expand_dims(train_images, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((28, 28, 1), ()), types: (tf.float64, tf.uint8)>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# 将数据转换为datasets\n",
    "train_datasets = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "train_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义参量，并进行数据乱序和batch批次化\n",
    "BATCH_SIZE = 256\n",
    "noise_dim = 100\n",
    "train_datasets = train_datasets.shuffle(60000).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 定义生成器和判别器模型"
   ]
  },
  {
   "source": [
    "由于涉及到计算卷积与反卷积尺寸计算的内容，因此记录如下：\n",
    ">1. 在TensorFlow2.1.0版本中，padding的same卷积后尺寸是否不变由步长strides是否大于1决定。对于转置卷积和卷积，padding的\"same\"与\"valid\"中，输入高宽（$i$），输出高宽（$o$），步长（$s$），卷积核的高宽（$k$）（设定高宽相等都为$k$）满足以下关系：\n",
    ">2. 卷积：\n",
    "    - padding = \"same\"时，$o = \\frac{i}{s}$, **向上取整**;\n",
    "    - padding = \"valid\"时，$o = \\frac{(i-k)}{s} + 1$, **向下取整**;\n",
    "    \n",
    ">3. 转置卷积：\n",
    "    - padding = \"same\"时，$o = i * s$;\n",
    "    - padding = \"valid\"时，$o = (i-1)*s+k$;\n",
    ">4. https://www.zhihu.com/question/60285234/answer/1002846390"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "    # 由于是两个输入，单纯的Sequential模型已经不能满足了，因此采用的是函数式API进行模型搭建\n",
    "    noise = tf.keras.layers.Input(shape=((noise_dim,)))\n",
    "    # 这里的标签值是一个单个的值，可以从train_datasets中可以看出来, 因此shape是一个()元祖\n",
    "    condition_label = tf.keras.layers.Input(shape=(()))\n",
    "    \n",
    "    # 需要将输入的noise和condition_label进行合并concat\n",
    "    # 在进行合并之前，由于condition_label的shape=()，不太好进行合并\n",
    "    # 因此需要使用Embedding函数将其转换成我们制定shape的一个向量才好进行合并\n",
    "    # 其中output_dim=100代表将condition_label映射到长度与noise长度相同的维度\n",
    "    # https://www.jianshu.com/p/e8986d0ff4ff\n",
    "    # https://blog.csdn.net/claroja/article/details/95196612\n",
    "    # 需要注意的是input_dim代表的是整个数据的词汇表的个数，这里整个MNIST数据集也就是10个数字\n",
    "    # 而input_length则代表每次输入的序列的长度。\n",
    "    x = tf.keras.layers.Embedding(input_dim=10, output_dim=100, \n",
    "                                  input_length=1)(condition_label)\n",
    "    # 将random vector与condition_label进行合并\n",
    "    x = tf.keras.layers.concatenate([noise, x])\n",
    "    # 合并完成之后，现在再利用全连接层将现在合并完之后的向量转换为合适shape的向量\n",
    "    # 方便后续以合适shape的向量为基准开始反卷积，直到反卷积到合适尺寸的图片大小\n",
    "    x = tf.keras.layers.Dense(units=3*3*128, use_bias=False)(x)\n",
    "    x = tf.keras.layers.Reshape(target_shape=(3, 3, 128))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    \n",
    "    # [7, 7, 64] 采用valid方式计算之后正好就是7 * 7大小\n",
    "    x = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=(3, 3), \n",
    "                                        strides=(2, 2), use_bias=False，                                                    padding='valid')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    \n",
    "    # [14, 14, 32]\n",
    "    x = tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=(3, 3), \n",
    "                                        strides=(2, 2), use_bias=False，                                                    padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    \n",
    "    # [28, 28, 1]\n",
    "    x = tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=(3, 3), \n",
    "                                        strides=(2, 2), use_bias=False,                                                     padding='same')(x)\n",
    "    # 因为输入的数据的范围是[-1, 1]，因此采用tanh\n",
    "    x = tf.keras.layers.Activation('tanh')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[noise, condition_label], outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_model():\n",
    "    # CGAN中discriminator在设计的时候对于condition_label的位置可以放在前面或者后面的\n",
    "    # 也就是说condition_label可以放在一开始图片输入的位置进行合并，然后一层层提取特征，直到最后进行概率判断\n",
    "    # 也可以等图片特征提取完毕开始准备传入到后续全连接层之前的时候进行合并，然后进行概率判断\n",
    "    # 与DCGAN不同的是，输入D的不光只有图片，还有想要的label\n",
    "    input_image = tf.keras.layers.Input(shape=((28,28,1)))\n",
    "    condition_label = tf.keras.layers.Input(shape=(()))\n",
    "    \n",
    "    x = tf.keras.layers.Embedding(input_dim=10, output_dim=28*28, \n",
    "                                  input_length=1)(condition_label)\n",
    "    x = tf.keras.layers.Reshape(target_shape=((28, 28, 1)))(x)\n",
    "    x = tf.keras.layers.concatenate([input_image, x])\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), strides=(2, 2), \n",
    "                               padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(rate=0.5)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), strides=(2, 2), \n",
    "                               padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(rate=0.5)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), strides=(2, 2), \n",
    "                               padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(rate=0.5)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    output_logits = tf.keras.layers.Dense(units=1)(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[input_image, condition_label],                                              outputs=output_logits)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 定义损失函数及优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = generator_model()\n",
    "discriminator = discriminator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Binary_Crossentropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_image_outputs, fake_image_outputs):\n",
    "    real_image_loss = Binary_Crossentropy(y_true=tf.ones_like(real_image_outputs),                                            y_pred=real_image_outputs)\n",
    "    fake_image_loss = Binary_Crossentropy(y_true=tf.zeros_like(fake_image_outputs),                                           y_pred=fake_image_outputs)\n",
    "    return real_image_loss + fake_image_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_image_outputs):\n",
    "    return Binary_Crossentropy(y_true=tf.ones_like(fake_image_outputs),                                            y_pred=fake_image_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 定义梯度更新函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    batchsize = labels.shape[0]\n",
    "    noise = tf.random.normal([batchsize, noise_dim])\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(inputs=(noise, labels), training=True)\n",
    "        fake_image_out = discriminator(inputs=(generated_images, labels),                                                  training=True)\n",
    "        real_image_out = discriminator(inputs=(images, labels), \n",
    "                                       training=True)\n",
    "        \n",
    "        generator_loss_ = generator_loss(fake_image_out)\n",
    "        discriminator_loss_ = discriminator_loss(real_image_out, fake_image_out)\n",
    "        \n",
    "    generator_gradients = gen_tape.gradient(generator_loss_,                                                                    generator.trainable_variables)\n",
    "    disciminator_gradients = disc_tape.gradient(discriminator_loss_,                                                                discriminator.trainable_variables)\n",
    "    \n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients,                                                                generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(disciminator_gradients,                                                             discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 定义辅助绘图函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置模型训练后期查看模型效果的noise和label，这里取定了之后可以在后续展示的时候展示一样的图片\n",
    "noise_seed = tf.random.normal([10, noise_dim])\n",
    "label_seed = np.random.randint(0, 10, size=(10, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_generator_images(model, noise, label, epoch_num):\n",
    "    print('现在是第%i个epoch.'%(epoch_num))\n",
    "    generated_images = model(inputs=(noise, label), training=False)\n",
    "    # 将shape为[None, 28, 28, 1]的图像转换为[None, 28, 28]\n",
    "    generated_images = tf.squeeze(generated_images)\n",
    "    fig = plt.figure(figsize=(10, 1))\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(1, 10, i+1)\n",
    "        plt.imshow((generated_images[i, :, :, :]+1)/2)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 定义模型训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(datasets, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch is:', epoch)\n",
    "        for images_batch, labels_batch in datasets:\n",
    "            train_step(images_batch, labels_batch)\n",
    "            print('.', end=' ')\n",
    "        print()\n",
    "        if epoch % 10 == 0:\n",
    "            plot_generator_images(generator, noise_seed, label_seed, epoch)\n",
    "    plot_generator_images(generator, noise_seed, label_seed, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_datasets, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save('generate_v2.h5')\n",
    "num = 10\n",
    "noise_seed = tf.random.normal([num, noise_dim])\n",
    "cat_seed = np.arange(10).reshape(-1, 1)\n",
    "print(cat_seed.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_images(generator, noise_seed, cat_seed, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_seed = np.array([3]*10)\n",
    "generate_images(generator, noise_seed, cat_seed, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_seed = np.array([6]*10)\n",
    "generate_images(generator, noise_seed, cat_seed, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}