{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF2.0 UNet语义分割模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ae0875ad9829>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 读取训练数据的图片\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_imgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../cityscapes/leftImg8bit/train/*/*.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# 读取训练数据的标签\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../cityscapes/gtFine/train/*/*_gtFine_labelIds.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'glob' is not defined"
     ]
    }
   ],
   "source": [
    "# 读取训练数据的图片\n",
    "train_imgs = glob.glob('../cityscapes/leftImg8bit/train/*/*.png')\n",
    "# 读取训练数据的标签\n",
    "train_labels = glob.glob('../cityscapes/gtFine/train/*/*_gtFine_labelIds.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_imgs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4cfbb9cfbf38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 对训练集进行乱序\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_imgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtrain_imgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_imgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_imgs' is not defined"
     ]
    }
   ],
   "source": [
    "# 对训练集进行乱序\n",
    "index = np.random.permutation(len(train_imgs))\n",
    "train_imgs = np.array(train_imgs)[index]\n",
    "train_labels = np.array(train_labels)[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取交叉验证数据的图片\n",
    "val_imgs = glob.glob('../cityscapes/leftImg8bit/val/*/*.png')\n",
    "# 读取交叉验证数据的标签\n",
    "val_labels = glob.glob('../cityscapes/gtFine/val/*/*_gtFine_labelIds.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建dataset\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices((train_imgs, train_labels))\n",
    "dataset_val = tf.data.Dataset.from_tensor_slices((val_imgs, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义读取图片的函数\n",
    "def read_png(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    return img\n",
    "\n",
    "# 定义读取标签的函数\n",
    "def read_png_label(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_png(img, channels=1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1 = read_png(train_imgs[0])\n",
    "label_1 = read_png_label(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据增强\n",
    "1. 随机翻转：img = tf.image.flip_left_right()\n",
    "2. 随机裁切：由于原始图像和分割标签图像是匹配的，所以需要将两者按照通道方向进行合并，然后再随机裁切，又由于图像比较大，如果直接塞到模型，可能显存不够用，因此可以将图像先resize到较小的尺寸，再在较小尺寸上进行随机裁切，这样获取到的图像视野能够比较大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img(img, mask):\n",
    "    # 先将原始图像和分割标签进行合并（沿着图像的通道方向）\n",
    "    concat_img = tf.concat([img, mask], axis=-1)\n",
    "    concat_img = tf.image.resize(concat_img, (280, 280), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    crop_img = tf.image.random_crop(concat_img, [256, 256, 4])\n",
    "    # 需要注意的是如果mask=crop_img[:, :, 3]，则返回的是一个二维的图像，channel维度被切片切掉了\n",
    "    # 而mask = crop_img[:, :, 3:]则代表channel那个维度的1会被保留下来\n",
    "    return crop_img[:, :, :3], crop_img[:, :, 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1, label_1 = crop_img(img_1, label_1)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img_1.numpy())\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(np.squeeze(label_1.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对输入的原始图像做归一化\n",
    "def normal(img, mask):\n",
    "    img = tf.cast(img, tf.float32) / 127.5 - 1\n",
    "    mask = tf.cast(mask, tf.int32)\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练数据\n",
    "def load_image_train(img_path, mask_path):\n",
    "    img = read_png(img_path)\n",
    "    mask = read_png_label(mask_path)\n",
    "    \n",
    "    img, mask = crop_img(img, mask)\n",
    "    \n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        img = tf.image.flip_left_right(img)\n",
    "        mask = tf.image.flip_left_right(mask)\n",
    "    \n",
    "    img, mask = normal(img, mask)\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载验证集数据\n",
    "def load_image_val(img_path, mask_path):\n",
    "    img = read_png(img_path)\n",
    "    mask = read_png_label(mask_path)\n",
    "    \n",
    "    img = tf.image.resize(img, (256, 256))\n",
    "    mask = tf.image.resize(mask, (256, 256))\n",
    "    \n",
    "    img, mask = normal(img, mask)\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_imgs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-930b81502414>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mBUFFER_SIZE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain_step_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_imgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mval_step_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_imgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_imgs' is not defined"
     ]
    }
   ],
   "source": [
    "# 定义模型的一些常量\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 300\n",
    "train_step_per_epoch = len(train_imgs) // BATCH_SIZE\n",
    "val_step_per_epoch = len(val_imgs) // BATCH_SIZE\n",
    "\n",
    "auto = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# 获取dataset\n",
    "dataset_train = dataset_train.map(load_image_train, num_parallel_calls=auto)\n",
    "dataset_val = dataset_val.map(load_image_val, num_parallel_calls=auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, m in dataset_train.take(1):\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow((img_1.numpy()+1)/2)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(np.squeeze(label_1.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = dataset_train.cache().repeat().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(auto)\n",
    "dataset_val = dataset_val.cache().batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. UNet模型搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看标签有多少类\n",
    "np.unique(label_1.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_model():\n",
    "    # UNet模型第一部分\n",
    "    inputs = tf.keras.layers.Input(shape=(256, 256, 3))\n",
    "    x_0 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu')(inputs)\n",
    "    x_0 = tf.keras.layers.BatchNormalization()(x_0)\n",
    "    x_0 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu')(x_0)\n",
    "    x_0 = tf.keras.layers.BatchNormalization()(x_0) # [256, 256, 64]\n",
    "    \n",
    "    # 下采样\n",
    "    x_1 = tf.keras.layers.MaxPooling2D()(x_0) # [128, 128, 64]\n",
    "    # 第二部分\n",
    "    x_1 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding='same', activation='relu')(x_1)\n",
    "    x_1 = tf.keras.layers.BatchNormalization()(x_1) \n",
    "    x_1 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding='same', activation='relu')(x_1)\n",
    "    x_1 = tf.keras.layers.BatchNormalization()(x_1) # [128, 128, 128]\n",
    "    \n",
    "    # 下采样\n",
    "    x_2 = tf.keras.layers.MaxPooling2D()(x_1) # [64, 64, 128]\n",
    "    # 第三部分\n",
    "    x_2 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same', activation='relu')(x_2)\n",
    "    x_2 = tf.keras.layers.BatchNormalization()(x_2) \n",
    "    x_2 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same', activation='relu')(x_2)\n",
    "    x_2 = tf.keras.layers.BatchNormalization()(x_2) # [64, 64, 256]\n",
    "    \n",
    "    # 下采样\n",
    "    x_3 = tf.keras.layers.MaxPooling2D()(x_2) # [32, 32, 256]\n",
    "    # 第四部分\n",
    "    x_3 = tf.keras.layers.Conv2D(filters=512, kernel_size=3, padding='same', activation='relu')(x_3)\n",
    "    x_3 = tf.keras.layers.BatchNormalization()(x_3) \n",
    "    x_3 = tf.keras.layers.Conv2D(filters=512, kernel_size=3, padding='same', activation='relu')(x_3)\n",
    "    x_3 = tf.keras.layers.BatchNormalization()(x_3) # [32, 32, 512]\n",
    "    \n",
    "    # 下采样\n",
    "    x_4 = tf.keras.layers.MaxPooling2D()(x_3) # [16, 16, 512]\n",
    "    # 第五部分\n",
    "    x_4 = tf.keras.layers.Conv2D(filters=1024, kernel_size=3, padding='same', activation='relu')(x_4)\n",
    "    x_4 = tf.keras.layers.BatchNormalization()(x_4) \n",
    "    x_4 = tf.keras.layers.Conv2D(filters=1024, kernel_size=3, padding='same', activation='relu')(x_4)\n",
    "    x_4 = tf.keras.layers.BatchNormalization()(x_4) # [16, 16, 1024]\n",
    "    \n",
    "    # ===================================================================\n",
    "    # 上采样(参数strides记得要设置，否则图像不会上采样扩大， 由于strides=2， 图像反卷积变为原来的一倍)\n",
    "    x_5 = tf.keras.layers.Conv2DTranspose(filters=512, kernel_size=3, strides=2, \n",
    "                                          padding='same', activation='relu')(x_4) \n",
    "    x_5 = tf.keras.layers.BatchNormalization()(x_5) # [32, 32, 512]\n",
    "    # 下采样的部分与现在的部分进行合并(concat，增加channel的厚度，与FCN中tf.add()不同)\n",
    "    x_6 = tf.concat([x_3, x_5], axis=-1) # [32, 32, 1024]\n",
    "    x_6 = tf.keras.layers.Conv2D(filters=512, kernel_size=3, padding='same', activation='relu')(x_6)\n",
    "    x_6 = tf.keras.layers.BatchNormalization()(x_6) \n",
    "    x_6 = tf.keras.layers.Conv2D(filters=512, kernel_size=3, padding='same', activation='relu')(x_6)\n",
    "    x_6 = tf.keras.layers.BatchNormalization()(x_6) # [32, 32, 512]\n",
    "    \n",
    "    # 上采样\n",
    "    x_7 = tf.keras.layers.Conv2DTranspose(filters=256, kernel_size=3, strides=2, \n",
    "                                          padding='same', activation='relu')(x_6) \n",
    "    x_7 = tf.keras.layers.BatchNormalization()(x_7) # [64, 54, 256]\n",
    "    # 下采样的部分与现在的部分进行合并\n",
    "    x_8 = tf.concat([x_2, x_7], axis=-1) # [64, 64, 512]\n",
    "    x_8 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same', activation='relu')(x_8)\n",
    "    x_8 = tf.keras.layers.BatchNormalization()(x_8) \n",
    "    x_8 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same', activation='relu')(x_8)\n",
    "    x_8 = tf.keras.layers.BatchNormalization()(x_8) # [64, 64, 256]\n",
    "    \n",
    "    # 上采样\n",
    "    x_9 = tf.keras.layers.Conv2DTranspose(filters=128, kernel_size=3, strides=2, \n",
    "                                          padding='same', activation='relu')(x_8) \n",
    "    x_9 = tf.keras.layers.BatchNormalization()(x_9) # [128, 128, 128]\n",
    "    # 下采样的部分与现在的部分进行合并\n",
    "    x_10 = tf.concat([x_1, x_9], axis=-1) # [128, 128, 256]\n",
    "    x_10 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding='same', activation='relu')(x_10)\n",
    "    x_10 = tf.keras.layers.BatchNormalization()(x_10) \n",
    "    x_10 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding='same', activation='relu')(x_10)\n",
    "    x_10 = tf.keras.layers.BatchNormalization()(x_10) # [128, 128, 128]\n",
    "    \n",
    "    # 上采样\n",
    "    x_11 = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=3, strides=2, \n",
    "                                          padding='same', activation='relu')(x_10) \n",
    "    x_11 = tf.keras.layers.BatchNormalization()(x_11) # [256, 256, 64]\n",
    "    # 下采样的部分与现在的部分进行合并\n",
    "    x_12 = tf.concat([x_0, x_11], axis=-1) # [256, 256, 128]\n",
    "    x_12 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu')(x_12)\n",
    "    x_12 = tf.keras.layers.BatchNormalization()(x_12) \n",
    "    x_12 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu')(x_12)\n",
    "    x_12 = tf.keras.layers.BatchNormalization()(x_12) # [256, 256, 64]\n",
    "    \n",
    "    # 最后输出层，34是分类类别数\n",
    "    outputs = tf.keras.layers.Conv2D(filters=34, kernel_size=1, \n",
    "                                     padding='same', activation='softmax')(x_12) # [256, 256, 34]\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 256, 256, 64) 1792        input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 256, 256, 64) 256         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 256, 256, 64) 36928       batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 256, 256, 64) 256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 128, 128, 64) 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 128, 128, 128 73856       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 128, 128, 128 512         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 128, 128 147584      batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 128, 128, 128 512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 64, 64, 128)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 256)  295168      max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 64, 64, 256)  1024        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 64, 256)  590080      batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 64, 64, 256)  1024        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 32, 32, 256)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 512)  1180160     max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32, 512)  2048        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 32, 32, 512)  2359808     batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 32, 512)  2048        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 16, 16, 512)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 1024) 4719616     max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 1024) 4096        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 1024) 9438208     batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 1024) 4096        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 32, 32, 512)  4719104     batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 32, 512)  2048        conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat (TensorFlowO [(None, 32, 32, 1024 0           batch_normalization_17[0][0]     \n",
      "                                                                 batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 32, 32, 512)  4719104     tf_op_layer_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32, 32, 512)  2048        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 512)  2359808     batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 32, 32, 512)  2048        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 64, 64, 256)  1179904     batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 64, 64, 256)  1024        conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_1 (TensorFlo [(None, 64, 64, 512) 0           batch_normalization_15[0][0]     \n",
      "                                                                 batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 64, 64, 256)  1179904     tf_op_layer_concat_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 64, 64, 256)  1024        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 64, 64, 256)  590080      batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 64, 64, 256)  1024        conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 128, 128, 128 295040      batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 128, 128, 128 512         conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_2 (TensorFlo [(None, 128, 128, 25 0           batch_normalization_13[0][0]     \n",
      "                                                                 batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 128, 128, 128 295040      tf_op_layer_concat_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 128, 128, 128 512         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 128, 128, 128 147584      batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 128, 128, 128 512         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 256, 256, 64) 73792       batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 256, 256, 64) 256         conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_3 (TensorFlo [(None, 256, 256, 12 0           batch_normalization_11[0][0]     \n",
      "                                                                 batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 256, 256, 64) 73792       tf_op_layer_concat_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 256, 256, 64) 256         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 256, 256, 64) 36928       batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 256, 256, 64) 256         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 256, 256, 34) 2210        batch_normalization_31[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 34,542,882\n",
      "Trainable params: 34,529,186\n",
      "Non-trainable params: 13,696\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = creat_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
