{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF2.0 UNet语义分割模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ae0875ad9829>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 读取训练数据的图片\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_imgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../cityscapes/leftImg8bit/train/*/*.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# 读取训练数据的标签\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../cityscapes/gtFine/train/*/*_gtFine_labelIds.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'glob' is not defined"
     ]
    }
   ],
   "source": [
    "# 读取训练数据的图片\n",
    "train_imgs = glob.glob('../cityscapes/leftImg8bit/train/*/*.png')\n",
    "# 读取训练数据的标签\n",
    "train_labels = glob.glob('../cityscapes/gtFine/train/*/*_gtFine_labelIds.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_imgs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4cfbb9cfbf38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 对训练集进行乱序\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_imgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtrain_imgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_imgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_imgs' is not defined"
     ]
    }
   ],
   "source": [
    "# 对训练集进行乱序\n",
    "index = np.random.permutation(len(train_imgs))\n",
    "train_imgs = np.array(train_imgs)[index]\n",
    "train_labels = np.array(train_labels)[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取交叉验证数据的图片\n",
    "val_imgs = glob.glob('../cityscapes/leftImg8bit/val/*/*.png')\n",
    "# 读取交叉验证数据的标签\n",
    "val_labels = glob.glob('../cityscapes/gtFine/val/*/*_gtFine_labelIds.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建dataset\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices((train_imgs, train_labels))\n",
    "dataset_val = tf.data.Dataset.from_tensor_slices((val_imgs, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义读取图片的函数\n",
    "def read_png(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    return img\n",
    "\n",
    "# 定义读取标签的函数\n",
    "def read_png_label(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_png(img, channels=1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1 = read_png(train_imgs[0])\n",
    "label_1 = read_png_label(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据增强\n",
    "1. 随机翻转：img = tf.image.flip_left_right()\n",
    "2. 随机裁切：由于原始图像和分割标签图像是匹配的，所以需要将两者按照通道方向进行合并，然后再随机裁切，又由于图像比较大，如果直接塞到模型，可能显存不够用，因此可以将图像先resize到较小的尺寸，再在较小尺寸上进行随机裁切，这样获取到的图像视野能够比较大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img(img, mask):\n",
    "    # 先将原始图像和分割标签进行合并（沿着图像的通道方向）\n",
    "    concat_img = tf.concat([img, mask], axis=-1)\n",
    "    concat_img = tf.image.resize(concat_img, (280, 280), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    crop_img = tf.image.random_crop(concat_img, [256, 256, 4])\n",
    "    # 需要注意的是如果mask=crop_img[:, :, 3]，则返回的是一个二维的图像，channel维度被切片切掉了\n",
    "    # 而mask = crop_img[:, :, 3:]则代表channel那个维度的1会被保留下来\n",
    "    return crop_img[:, :, :3], crop_img[:, :, 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1, label_1 = crop_img(img_1, label_1)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img_1.numpy())\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(np.squeeze(label_1.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对输入的原始图像做归一化\n",
    "def normal(img, mask):\n",
    "    img = tf.cast(img, tf.float32) / 127.5 - 1\n",
    "    mask = tf.cast(mask, tf.int32)\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练数据\n",
    "def load_image_train(img_path, mask_path):\n",
    "    img = read_png(img_path)\n",
    "    mask = read_png_label(mask_path)\n",
    "    \n",
    "    img, mask = crop_img(img, mask)\n",
    "    \n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        img = tf.image.flip_left_right(img)\n",
    "        mask = tf.image.flip_left_right(mask)\n",
    "    \n",
    "    img, mask = normal(img, mask)\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载验证集数据\n",
    "def load_image_val(img_path, mask_path):\n",
    "    img = read_png(img_path)\n",
    "    mask = read_png_label(mask_path)\n",
    "    \n",
    "    img = tf.image.resize(img, (256, 256))\n",
    "    mask = tf.image.resize(mask, (256, 256))\n",
    "    \n",
    "    img, mask = normal(img, mask)\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_imgs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-930b81502414>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mBUFFER_SIZE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain_step_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_imgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mval_step_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_imgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_imgs' is not defined"
     ]
    }
   ],
   "source": [
    "# 定义模型的一些常量\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 300\n",
    "train_step_per_epoch = len(train_imgs) // BATCH_SIZE\n",
    "val_step_per_epoch = len(val_imgs) // BATCH_SIZE\n",
    "\n",
    "auto = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# 获取dataset\n",
    "dataset_train = dataset_train.map(load_image_train, num_parallel_calls=auto)\n",
    "dataset_val = dataset_val.map(load_image_val, num_parallel_calls=auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, m in dataset_train.take(1):\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow((img_1.numpy()+1)/2)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(np.squeeze(label_1.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = dataset_train.cache().repeat().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(auto)\n",
    "dataset_val = dataset_val.cache().batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. UNet模型搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看标签有多少类\n",
    "np.unique(label_1.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_model():\n",
    "    # UNet模型第一部分\n",
    "    inputs = tf.keras.layers.Input(shape=(256, 256, 3))\n",
    "    x_0 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu')(inputs)\n",
    "    x_0 = tf.keras.layers.BatchNormalization()(x_0)\n",
    "    x_0 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu')(x_0)\n",
    "    x_0 = tf.keras.layers.BatchNormalization()(x_0) # [256, 256, 64]\n",
    "    \n",
    "    # 下采样\n",
    "    x_1 = tf.keras.layers.MaxPooling2D()(x_0) # [128, 128, 64]\n",
    "    # 第二部分\n",
    "    x_1 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding='same', activation='relu')(x_1)\n",
    "    x_1 = tf.keras.layers.BatchNormalization()(x_1) \n",
    "    x_1 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding='same', activation='relu')(x_1)\n",
    "    x_1 = tf.keras.layers.BatchNormalization()(x_1) # [128, 128, 128]\n",
    "    \n",
    "    # 下采样\n",
    "    x_2 = tf.keras.layers.MaxPooling2D()(x_1) # [64, 64, 128]\n",
    "    # 第三部分\n",
    "    x_2 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same', activation='relu')(x_2)\n",
    "    x_2 = tf.keras.layers.BatchNormalization()(x_2) \n",
    "    x_2 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same', activation='relu')(x_2)\n",
    "    x_2 = tf.keras.layers.BatchNormalization()(x_2) # [64, 64, 256]\n",
    "    \n",
    "    # 下采样\n",
    "    x_3 = tf.keras.layers.MaxPooling2D()(x_2) # [32, 32, 256]\n",
    "    # 第四部分\n",
    "    x_3 = tf.keras.layers.Conv2D(filters=512, kernel_size=3, padding='same', activation='relu')(x_3)\n",
    "    x_3 = tf.keras.layers.BatchNormalization()(x_3) \n",
    "    x_3 = tf.keras.layers.Conv2D(filters=512, kernel_size=3, padding='same', activation='relu')(x_3)\n",
    "    x_3 = tf.keras.layers.BatchNormalization()(x_3) # [32, 32, 512]\n",
    "    \n",
    "    # 下采样\n",
    "    x_4 = tf.keras.layers.MaxPooling2D()(x_3) # [16, 16, 512]\n",
    "    # 第五部分\n",
    "    x_4 = tf.keras.layers.Conv2D(filters=1024, kernel_size=3, padding='same', activation='relu')(x_4)\n",
    "    x_4 = tf.keras.layers.BatchNormalization()(x_4) \n",
    "    x_4 = tf.keras.layers.Conv2D(filters=1024, kernel_size=3, padding='same', activation='relu')(x_4)\n",
    "    x_4 = tf.keras.layers.BatchNormalization()(x_4) # [16, 16, 1024]\n",
    "    \n",
    "    # ===================================================================\n",
    "    # 上采样(参数strides记得要设置，否则图像不会上采样扩大， 由于strides=2， 图像反卷积变为原来的一倍)\n",
    "    x_5 = tf.keras.layers.Conv2DTranspose(filters=512, kernel_size=3, strides=2, \n",
    "                                          padding='same', activation='relu')(x_4) \n",
    "    x_5 = tf.keras.layers.BatchNormalization()(x_5) # [32, 32, 512]\n",
    "    # 下采样的部分与现在的部分进行合并(concat，增加channel的厚度，与FCN中tf.add()不同)\n",
    "    x_6 = tf.concat([x_3, x_5], axis=-1) # [32, 32, 1024]\n",
    "    x_6 = tf.keras.layers.Conv2D(filters=512, kernel_size=3, padding='same', activation='relu')(x_6)\n",
    "    x_6 = tf.keras.layers.BatchNormalization()(x_6) \n",
    "    x_6 = tf.keras.layers.Conv2D(filters=512, kernel_size=3, padding='same', activation='relu')(x_6)\n",
    "    x_6 = tf.keras.layers.BatchNormalization()(x_6) # [32, 32, 512]\n",
    "    \n",
    "    # 上采样\n",
    "    x_7 = tf.keras.layers.Conv2DTranspose(filters=256, kernel_size=3, strides=2, \n",
    "                                          padding='same', activation='relu')(x_6) \n",
    "    x_7 = tf.keras.layers.BatchNormalization()(x_7) # [64, 54, 256]\n",
    "    # 下采样的部分与现在的部分进行合并\n",
    "    x_8 = tf.concat([x_2, x_7], axis=-1) # [64, 64, 512]\n",
    "    x_8 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same', activation='relu')(x_8)\n",
    "    x_8 = tf.keras.layers.BatchNormalization()(x_8) \n",
    "    x_8 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same', activation='relu')(x_8)\n",
    "    x_8 = tf.keras.layers.BatchNormalization()(x_8) # [64, 64, 256]\n",
    "    \n",
    "    # 上采样\n",
    "    x_9 = tf.keras.layers.Conv2DTranspose(filters=128, kernel_size=3, strides=2, \n",
    "                                          padding='same', activation='relu')(x_8) \n",
    "    x_9 = tf.keras.layers.BatchNormalization()(x_9) # [128, 128, 128]\n",
    "    # 下采样的部分与现在的部分进行合并\n",
    "    x_10 = tf.concat([x_1, x_9], axis=-1) # [128, 128, 256]\n",
    "    x_10 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding='same', activation='relu')(x_10)\n",
    "    x_10 = tf.keras.layers.BatchNormalization()(x_10) \n",
    "    x_10 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding='same', activation='relu')(x_10)\n",
    "    x_10 = tf.keras.layers.BatchNormalization()(x_10) # [128, 128, 128]\n",
    "    \n",
    "    # 上采样\n",
    "    x_11 = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=3, strides=2, \n",
    "                                          padding='same', activation='relu')(x_10) \n",
    "    x_11 = tf.keras.layers.BatchNormalization()(x_11) # [256, 256, 64]\n",
    "    # 下采样的部分与现在的部分进行合并\n",
    "    x_12 = tf.concat([x_0, x_11], axis=-1) # [256, 256, 128]\n",
    "    x_12 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu')(x_12)\n",
    "    x_12 = tf.keras.layers.BatchNormalization()(x_12) \n",
    "    x_12 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu')(x_12)\n",
    "    x_12 = tf.keras.layers.BatchNormalization()(x_12) # [256, 256, 64]\n",
    "    \n",
    "    # 最后输出层，34是分类类别数\n",
    "    outputs = tf.keras.layers.Conv2D(filters=34, kernel_size=1, \n",
    "                                     padding='same', activation='softmax')(x_12) # [256, 256, 34]\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 256, 256, 64) 1792        input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 256, 256, 64) 256         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 256, 256, 64) 36928       batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 256, 256, 64) 256         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling2D) (None, 128, 128, 64) 0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 128, 128, 128 73856       max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 128, 128, 128 512         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 128, 128, 128 147584      batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 128, 128, 128 512         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling2D) (None, 64, 64, 128)  0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 64, 64, 256)  295168      max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 64, 64, 256)  1024        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 64, 64, 256)  590080      batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 64, 64, 256)  1024        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling2D) (None, 32, 32, 256)  0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 32, 32, 512)  1180160     max_pooling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 32, 32, 512)  2048        conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 32, 32, 512)  2359808     batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 32, 32, 512)  2048        conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling2D) (None, 16, 16, 512)  0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 16, 16, 1024) 4719616     max_pooling2d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 16, 16, 1024) 4096        conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 16, 16, 1024) 9438208     batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 16, 16, 1024) 4096        conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_16 (Conv2DTran (None, 32, 32, 512)  4719104     batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 32, 32, 512)  2048        conv2d_transpose_16[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_16 (TensorFl [(None, 32, 32, 1024 0           batch_normalization_105[0][0]    \n",
      "                                                                 batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 32, 32, 512)  4719104     tf_op_layer_concat_16[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 32, 32, 512)  2048        conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 32, 32, 512)  2359808     batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 32, 32, 512)  2048        conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_17 (Conv2DTran (None, 64, 64, 256)  1179904     batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 64, 64, 256)  1024        conv2d_transpose_17[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_17 (TensorFl [(None, 64, 64, 512) 0           batch_normalization_103[0][0]    \n",
      "                                                                 batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 64, 64, 256)  1179904     tf_op_layer_concat_17[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 64, 64, 256)  1024        conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 64, 64, 256)  590080      batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 64, 64, 256)  1024        conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_18 (Conv2DTran (None, 128, 128, 128 295040      batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 128, 128, 128 512         conv2d_transpose_18[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_18 (TensorFl [(None, 128, 128, 25 0           batch_normalization_101[0][0]    \n",
      "                                                                 batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 128, 128, 128 295040      tf_op_layer_concat_18[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 128, 128, 128 512         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 128, 128, 128 147584      batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 128, 128, 128 512         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_19 (Conv2DTran (None, 256, 256, 64) 73792       batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 256, 256, 64) 256         conv2d_transpose_19[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_19 (TensorFl [(None, 256, 256, 12 0           batch_normalization_99[0][0]     \n",
      "                                                                 batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 256, 256, 64) 73792       tf_op_layer_concat_19[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 256, 256, 64) 256         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 256, 256, 64) 36928       batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 256, 256, 64) 256         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 256, 256, 34) 2210        batch_normalization_119[0][0]    \n",
      "==================================================================================================\n",
      "Total params: 34,542,882\n",
      "Trainable params: 34,529,186\n",
      "Non-trainable params: 13,696\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = creat_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanIoU(tf.keras.metrics.MeanIoU):\n",
    "    def __call__(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.argmax(y_pred, axis=-1)\n",
    "        return super().__call__(y_true, y_pred, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置模型\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['acc', MeanIoU(num_classes=34)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 60\n",
    "history = model.fit(dataset_train, \n",
    "                    epochs=EPOCHS,\n",
    "                    steps_per_epoch=train_step_per_epoch,\n",
    "                    validation_steps=val_step_per_epoch,\n",
    "                    validation_data=dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(EPOCHS)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'r', label='Training_loss')\n",
    "plt.plot(epochs, val_loss, 'bo', label='Validation_loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看模型训练完毕之后的效果\n",
    "num = 3\n",
    "for image, mask in dataset_val.take(1):\n",
    "    pred_mask = model.predict(image)\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(num):\n",
    "        plt.subplot(num, 3, i*num+1)\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(image[i]))\n",
    "        plt.subplot(num, 3, i*num+2)\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(mask[i]))\n",
    "        plt.subplot(num, 3, i*num+3)\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(pred_mask[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
