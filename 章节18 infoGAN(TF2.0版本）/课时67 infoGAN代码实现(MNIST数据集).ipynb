{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 课时67 infoGAN代码实现(MNIST数据集)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 读取数据以及数据预处理\n",
    ">需要注意的是在infoGAN中输入的condition和CGAN中的是不一样的，CGAN中的是和输入图片一一对应的了label信息，而infoGAN中的condition则是维度大小一致的任意一个向量而已(随机的noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x247301b3908>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 导入MNIST数据集\n",
    "(train_images, train_labels),(_, _) = tf.keras.datasets.mnist.load_data()\n",
    "plt.imshow(train_images[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对数据集进行预处理(数据归一化到[-1, 1])\n",
    "train_images = train_images/127.5 - 1\n",
    "# 这里CGAN采用的是DCGAN的结构，也就是卷积，因此需要将图片数据的第三个维度扩充起来\n",
    "train_images = np.expand_dims(train_images, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((28, 28, 1), ()), types: (tf.float64, tf.uint8)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将数据转换为datasets\n",
    "train_datasets = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "train_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义参量，并进行数据乱序和batch批次化\n",
    "BATCH_SIZE = 256\n",
    "noise_dim = 100\n",
    "infoGAN_condition_dim = 100\n",
    "train_datasets = train_datasets.shuffle(train_images.shape[0]).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float64, tf.uint8)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 定义生成器和判别器模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "    # 由于是三个输入，因此采用的是函数式API进行模型搭建\n",
    "    noise = tf.keras.layers.Input(shape=((noise_dim,)))\n",
    "    # 这里的标签值是一个单个的值，可以从train_datasets中可以看出来\n",
    "    # 这个输入是label，是在这次试验中额外加入的可以控制生成图片能够生成对应的数据的标签\n",
    "    # 这个输入与CGAN/ACGAN中一样，仅本试验中进行添加，实际的infoGAN中没有这一输入\n",
    "    CGAN_condition_label = tf.keras.layers.Input(shape=(()))\n",
    "    # 这个就是infoGAN中输入的C，也即latent space vector\n",
    "    # 另外：需要注意的是infoGAN中的C一开始是不清楚它到底控制的是数据的什么方面的，需要进行测试\n",
    "    # 此外，要想控制数据更多的特性的话，就增加这个infoGAN_C的个数输入到G，不同的C控制不同的特性\n",
    "    infoGAN_condition_label = tf.keras.layers.Input(shape=(infoGAN_condition_dim))\n",
    "    \n",
    "    # 需要将输入的noise和condition_label进行合并concat\n",
    "    # 在进行合并之前，由于condition_label的shape=()，不太好进行合并\n",
    "    # 因此需要使用Embedding函数将其转换成我们制定shape的一个向量才好进行合并\n",
    "    # 其中output_dim=100代表将condition_label映射到长度与noise长度相同的维度\n",
    "    # https://www.jianshu.com/p/e8986d0ff4ff\n",
    "    # https://blog.csdn.net/claroja/article/details/95196612\n",
    "    # 需要注意的是input_dim代表的是整个数据的词汇表的个数，这里整个MNIST数据集也就是10个数字\n",
    "    # 而input_length则代表每次输入的序列的长度。\n",
    "    x = tf.keras.layers.Embedding(input_dim=10, output_dim=100, \n",
    "                                  input_length=1)(CGAN_condition_label)\n",
    "    x = tf.keras.layers.concatenate([noise, x, infoGAN_condition_label])\n",
    "    # 合并完成之后，现在再利用全连接层将现在合并完之后的向量转换为合适shape的向量\n",
    "    # 方便后续以合适shape的向量为基准开始反卷积，知道反卷积到合适尺寸的图片大小\n",
    "    x = tf.keras.layers.Dense(units=3*3*128, use_bias=False)(x)\n",
    "    x = tf.keras.layers.Reshape(target_shape=(3, 3, 128))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    \n",
    "    # [7, 7, 64]\n",
    "    x = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=(3, 3), \n",
    "                                        strides=(2, 2), use_bias=False,                                                     padding='valid')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    \n",
    "    # [14, 14, 32]\n",
    "    x = tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=(3, 3), \n",
    "                                        strides=(2, 2), use_bias=False,                                                     padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    \n",
    "    # [28, 28, 1]\n",
    "    x = tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=(3, 3), \n",
    "                                        strides=(2, 2), use_bias=False,                                                     padding='same')(x)\n",
    "    x = tf.keras.layers.Activation('tanh')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[noise, \n",
    "                                   CGAN_condition_label,                                                               infoGAN_condition_label], \n",
    "                           outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_model():\n",
    "    # infoGAN中D网络和Q网络可以是共享的网络\n",
    "    input_image = tf.keras.layers.Input(shape=((28,28,1)))\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), strides=(2, 2), \n",
    "                               padding='same', use_bias=False)(input_image)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(rate=0.5)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), strides=(2, 2), \n",
    "                               padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(rate=0.5)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), strides=(2, 2), \n",
    "                               padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(rate=0.5)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    # 图片真假(real/fake)输出\n",
    "    real_or_fake_outputs_logits = tf.keras.layers.Dense(units=1)(x)\n",
    "    # 图片类别判断输出(MNIST是十分类)\n",
    "    category_outputs_logits = tf.keras.layers.Dense(units=10)(x)\n",
    "    # 图片的condition_label输出\n",
    "    condition_outputs_logits = tf.keras.layers.Dense(units=infoGAN_condition_dim)(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_image, \n",
    "                           outputs=[real_or_fake_outputs_logits,                                                        category_outputs_logits, \n",
    "                                    condition_outputs_logits])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 定义损失函数及优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = generator_model()\n",
    "discriminator = discriminator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Binary_Crossentropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "# 增加图片类别分类损失(SparseCategoricalCrossentropy)\n",
    "Category_Cross_Entropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_image_outputs, pred_class_outs, \n",
    "                       fake_image_outputs, real_class_label,                                               condition_outputs_logits, condition_inputs):\n",
    "    real_image_loss = Binary_Crossentropy(y_true=tf.ones_like(real_image_outputs),                                            y_pred=real_image_outputs)\n",
    "    fake_image_loss = Binary_Crossentropy(y_true=tf.zeros_like(fake_image_outputs),                                           y_pred=fake_image_outputs)\n",
    "    \n",
    "    # 由于在本次试验中添加了ACGAN/CGAN中的标签输入，因此额外增加了多类别分类损失\n",
    "    category_loss = Category_Cross_Entropy(y_true=real_class_label,                                                            y_pred=pred_class_outs)\n",
    "    # 这个损失就是用来衡量info中输入G的latent_C和判别网络中\n",
    "    # 将G_image作为输入而输出的latent_C之间的误差有多大，两者要尽量一致，因此采用平方损失\n",
    "    condition_loss = tf.reduce_mean(tf.square(condition_inputs -                                                        condition_outputs_logits))\n",
    "    \n",
    "    d_total_loss = real_image_loss + fake_image_loss \n",
    "                 + category_loss + condition_loss\n",
    "    return d_total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_image_outputs, pred_class_outs, real_class_label, \n",
    "                   condition_outputs_logits, condition_inputs):\n",
    "    fake_image_loss = Binary_Crossentropy(y_true=tf.ones_like(fake_image_outputs),                                            y_pred=fake_image_outputs)\n",
    "    category_loss = Category_Cross_Entropy(y_true=real_class_label,                                                            y_pred=pred_class_outs)\n",
    "    condition_loss = tf.reduce_mean(tf.square(condition_inputs -                                                        condition_outputs_logits))\n",
    "    \n",
    "    g_total_loss = fake_image_loss + category_loss + condition_loss\n",
    "    \n",
    "    return g_total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 定义梯度更新函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    batchsize = labels.shape[0]\n",
    "    noise = tf.random.normal([batchsize, noise_dim])\n",
    "    condition = tf.random.normal([batchsize, infoGAN_condition_dim])\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(inputs=(noise, labels, condition),                                                  training=True)\n",
    "        fake_image_out, fake_class_outs, condition_out = discriminator  (inputs=generated_images, training=True)\n",
    "        real_image_out, real_class_outs, _ = discriminator(inputs=images,                                                                      training=True)\n",
    "        \n",
    "        generator_loss_ = generator_loss(fake_image_out, fake_class_outs, labels, \n",
    "                                         condition_out, condition)\n",
    "        discriminator_loss_ = discriminator_loss(real_image_out, real_class_outs,                                                    fake_image_out, labels,                                                             condition_out, condition)\n",
    "        \n",
    "    generator_gradients = gen_tape.gradient(generator_loss_,                                                                    generator.trainable_variables)\n",
    "    disciminator_gradients = disc_tape.gradient(discriminator_loss_,                                                                discriminator.trainable_variables)\n",
    "    \n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients,                                                                generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(disciminator_gradients,                                                             discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 定义辅助绘图函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置模型训练后期查看模型效果的noise和label，这里取定了之后可以在后续展示的时候展示一样的图片\n",
    "noise_seed = tf.random.normal([10, noise_dim])\n",
    "label_seed = np.random.randint(0, 10, size=(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_generator_images(model, noise, label, epoch_num, condition):\n",
    "    print('现在是第%i个epoch.'%(epoch_num))\n",
    "    generated_images = model(inputs=(noise, label, condition), training=False)\n",
    "    # 将shape为[None, 28, 28, 1]的图像转换为[None, 28, 28]\n",
    "    generated_images = tf.squeeze(generated_images)\n",
    "    fig = plt.figure(figsize=(10, 1))\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(1, 10, i+1)\n",
    "        plt.imshow((generated_images[i, :, :]+1)/2, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 定义模型训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(datasets, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch is:', epoch)\n",
    "        for images_batch, labels_batch in datasets:\n",
    "            train_step(images_batch, labels_batch)\n",
    "            print('.', end=' ')\n",
    "        print()\n",
    "        if epoch % 10 == 0:\n",
    "            condition = tf.random.normal([10, infoGAN_condition_dim])\n",
    "            plot_generator_images(generator, noise_seed, \n",
    "                                  label_seed, epoch, condition)\n",
    "    condition = tf.random.normal([10, infoGAN_condition_dim])\n",
    "    plot_generator_images(generator, noise_seed, label_seed, epoch, condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_datasets, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行测试\n",
    "generator.save('generate_infogan.h5')\n",
    "num = 10\n",
    "\n",
    "noise_seed = tf.random.normal([num, noise_dim])\n",
    "cond = tf.convert_to_tensor(np.ones([num, infoGAN_condition_dim])*0.1)\n",
    "cat_seed = np.arange(10).reshape(-1, 1)\n",
    "\n",
    "plot_generator_images(generator, noise_seed, cat_seed, 0, cond)\n",
    "print(cat_seed.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_seed = np.array([3]*10)\n",
    "plot_generator_images(generator, noise_seed, cat_seed, 0, cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = tf.convert_to_tensor(np.ones([num, infoGAN_condition_dims])*0.9)\n",
    "plot_generator_images(generator, noise_seed, cat_seed, 0, cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = tf.convert_to_tensor(np.linspace(0, 1, 300).reshape(10, 30))\n",
    "plot_generator_images(generator, noise_seed, cat_seed, 0, cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_seed = np.array([5]*10)\n",
    "plot_generator_images(generator, noise_seed, cat_seed, 0, cond)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "24a5e97bb7b9e502cdc0a8f9a9ca55a530ba47ae30463d9079b7951f45a334c6"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}